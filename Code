# Importing Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.impute import SimpleImputer  # For handling missing values
from sklearn.preprocessing import StandardScaler  # For feature scaling

# Load Dataset
data = pd.read_csv('/mnt/data/used_cars.csv')

# Inspecting the Dataset
print(data.head())
print(data.info())
print(data.describe())

# Cleaning and Processing the Data
# Removing '$' and ',' from 'price' and converting to numeric
data['price'] = data['price'].replace('[\$,]', '', regex=True).astype(float)

# Removing ',' and ' mi.' from 'milage' and converting to numeric
data['milage'] = data['milage'].replace('[\, mi.]', '', regex=True).astype(float)

# Extracting engine capacity from 'engine' column
data['engine'] = data['engine'].str.extract(r'(\d+\.\d+)').astype(float)

# Encoding Categorical Variables
data = pd.get_dummies(data, columns=['brand', 'fuel_type', 'transmission'], drop_first=True)

# Dropping Irrelevant Columns
data = data.drop(columns=['model', 'ext_col', 'int_col', 'accident', 'clean_title'])

# Handling Missing Values
imputer = SimpleImputer(strategy='mean')
data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)

# Exploratory Data Analysis
# Correlation Heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(data.corr(), cmap='coolwarm', annot=False, fmt='.2f')
plt.title("Correlation Heatmap")
plt.show()

# Splitting Features and Target Variable
X = data.drop(columns=['price'])
y = data['price']

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Feature Scaling
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Random Forest Regressor
rf = RandomForestRegressor(random_state=42)
rf.fit(X_train, y_train)
rf_pred = rf.predict(X_test)

# Random Forest Evaluation
rf_mae = mean_absolute_error(y_test, rf_pred)
rf_r2 = r2_score(y_test, rf_pred)
print(f"Random Forest Regressor - MAE: {rf_mae:.2f}, R2: {rf_r2:.2f}")

# ROC Curve (Random Forest does not directly provide probabilities for regression)
plt.figure(figsize=(8, 6))
plt.scatter(y_test, rf_pred, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual vs Predicted Prices")
plt.show()

# Hyperparameter Tuning for Random Forest (Grid Search Example)
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10]
}
grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring='neg_mean_absolute_error')
grid_search.fit(X_train, y_train)
best_rf = grid_search.best_estimator_
best_rf_pred = best_rf.predict(X_test)

# Evaluation for Best Model
best_rf_mae = mean_absolute_error(y_test, best_rf_pred)
best_rf_r2 = r2_score(y_test, best_rf_pred)
print(f"Best Random Forest Regressor - MAE: {best_rf_mae:.2f}, R2: {best_rf_r2:.2f}")

# Plotting Actual vs Predicted for Best Model
plt.figure(figsize=(8, 6))
plt.scatter(y_test, best_rf_pred, alpha=0.6, label='Predictions')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--', label='Perfect Fit')
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Best Model - Actual vs Predicted Prices")
plt.legend()
plt.show()
